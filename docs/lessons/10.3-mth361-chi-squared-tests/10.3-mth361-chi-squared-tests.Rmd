---
title: "Chi-Squared Tests"
subtitle: "Applied Statistics"
author: "MTH-361A | Spring 2025 | University of Portland"
date: "March 21, 2025"
output:
  slidy_presentation:
    font_adjustment: +5
    footer: "| MTH-361A Spring 2025 | <a href='../../index.html'>Back to the Course Website</a>"
    css: ../_style.css
bibliography: ../../references.bib
csl: ../../apa.csl
nocite: '@*'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r echo=FALSE, eval=TRUE,message=FALSE, warning=FALSE}
library(tidyverse)
library(openintro)
library(gridExtra)
library(latex2exp)
data(COL)
seed <- 42
```

## Objectives

:::: {.column width=15%}
::::

:::: {.column width=70%}
- **Develop an understanding of using the chi-squared distribution**
- **Know how to conduct and interpret chi-squared test results**
- **Activity: Test Independence for Two-Way Tables**
::::

:::: {.column width=15%}
::::

## Previously... 

**Confidence Interval for One Proportion**

$$\hat{p} \pm z^{\star} \text{SE}_{\hat{p}}$$

\[
\begin{aligned}
\hat{p} & \longrightarrow \text{sample proportion (or the point estimate)} \\
z^{\star} & \longrightarrow \text{critical z-score at a given confidence level} \\
\text{SE}_{\hat{p}} & \longrightarrow \text{standard error of the sampling distribution} \\
\end{aligned}
\]

**Hypothesis Testing for One Proportion**

\[
\begin{aligned}
p & \longrightarrow \text{population proportion} \\
\hat{p} & \longrightarrow \text{sample proportion (or the point estimate)} \\
H_0: p = p_0 & \longrightarrow \text{null hypothesis}  \\
H_A: p \ne p_0 & \longrightarrow \text{alternative hypothesis (can be } < \text{ or } > \text{)} \\
z & \longrightarrow \text{test statistic} \\
\text{SE}_{p} & \longrightarrow \text{standard error of the null distribution} \\
\end{aligned}
\]

## The Chi-Squared Statistic

The **Chi-Square statistic** is used in hypothesis testing to determine whether observed data differs significantly from expected data. Commonly used for categorical data analysis.

$$\chi^2 = \sum \frac{(O-E)^2}{E}$$

* $O$ is the observed frequency
* $E$ is the expected frequency

## The Chi-Squared Distribution

```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=7,fig.height=3,out.width='100%'}
# normal pdf
df <- 4
x_chisq <- seq(0,30,0.10)
chisq_pdf <- dchisq(x_chisq,df)

# convert pdf into tibble
df_chisq <- tibble(z=x_chisq, chisq_pdf=chisq_pdf)

# plot the Bernoulli distribution and store it into a R variable
p1 <- ggplot(df_chisq,aes(x=z,y=chisq_pdf)) + 
  geom_line(color="#009159",linewidth=1) + 
  xlab(TeX("$\\chi^2$")) +
  ylab("density") + 
  ggtitle("Chi-Squared Distribution with 4 Degrees of Freedom") + # sets the title of the plot
  scale_x_discrete(limits=c(-1.75)) + 
  theme_minimal() + # set theme of entire plot
  theme(legend.title=element_blank())

# display plot
p1
```

## Example 1

Consider the following problem description.

> Students in grades 4-6 were asked whether good grades, athletic ability, or popularity was most important to them. A two-way table separating the students by grade and by choice of most important factor is shown below. Do these data provide evidence to suggest that goals vary by grade?

<center>
|  | Grade | Popular | Sports |
|:---:|:---:|:---:|:---:|
| 4th | 63 | 31 | 23 |
| 5th | 88 | 55 | 33 |
| 6th | 96 | 55 | 32 |
</center>

Source: [Popular Kids Dataset](https://stat-jet-asu.github.io/Datasets/InstructorDescriptions/popular.html){target="_blank"}. This is from a 1992 study and was revisited 30 years later.

## Example 1: The Chi-Squared Test for Independence (1/2)

  * The null and alternative Hypothesis
    $$H_0: \text{Grade and goals are independent.  Goals do not vary by grade.}$$
  	$$H_A: \text{Grade and goals are dependent.  Goals vary by grade}$$
  	
## Example 1: The Chi-Squared Test for Independence (2/2)	
  	
  * The Chi-Squared test statistic
    $$\chi^2_{k} = \sum_{i=1}^n \frac{(O_i - E_i)^2}{E_i}$$
    - $O_i$ is the number of observations of type $i$
    - $E_i$ is the expected frequency of type $i$
    - $n$ is the number of cells in the table
    - $k = (R-1)(C-1)$ is the degrees of freedom where $R$ is the number of rows and C is the number of columns.

## Example 1: Computing the $\chi^2$ statistic - Expected Frequency (1/3)

  * Start with the expected frequency of type $i$

<div class='left' style='float:left;width:48%'>
  <center>
|  | Grade | Popular | Sports | Total |
|:---:|:---:|:---:|:---:|:---:|
| 4th | $\color{blue}{63}$ | $\color{orange}{31}$ | 23 | 119 |
| 5th | 88 | 55 | 33 | 176 |
| 6th | 96 | 55 | $\color{red}{32}$ | 183 |
| Total | 247 | 141 | 90 | 478 |
</center>

Note: Color corresponds to the cell and we are rounding to the nearest integer for computing the expected frequencies.
</div>

<div class='right' style='float:right;width:48%'>
$$\color{blue}{E_{4th,Grade} = \frac{(119)(247)}{478} = 61}$$
$$\color{orange}{E_{4th,Popular} = \frac{(119)(141)}{478} = 35}$$
$$\vdots$$
$$\color{red}{E_{6th,Sports} = \frac{(183)(90)}{478} = 34}$$
</div>

## Example 1: Computing the $\chi^2$ statistic - Expected Frequency (2/3)

  * Question - What is the expected count for the highlighted cell?
  
<center>
|  | Grade | Popular | Sports | Total |
|:---:|:---:|:---:|:---:|:---:|
| 4th | 63 | 31 | 23 | 119 |
| 5th | 88 | $\color{green}{55}$ | 33 | 176 |
| 6th | 96 | 55 | 32 | 183 |
| Total | 247 | 141 | 90 | 478 |
</center>

  >- $$\color{green}{E_{5th,Popular} = \frac{(176)(141)}{478} = 52}$$

## Example 1: Computing the $\chi^2$ statistic - Expected Frequency (3/3)

  * The expected frequency for each $\color{blue}{[cell]}$.

|  | Grade | Popular | Sports | Total |
|:---:|:---:|:---:|:---:|:---:|
| 4th | 63 $\color{blue}{[61]}$ | 31 $\color{blue}{[35]}$ | 23 $\color{blue}{[23]}$ | 119 |
| 5th | 88 $\color{blue}{[91]}$ | 55 $\color{blue}{[52]}$ | 33 $\color{blue}{[33]}$ | 176 |
| 6th | 96 $\color{blue}{[95]}$ | 55 $\color{blue}{[54]}$ | 32 $\color{blue}{[34]}$ | 183 |
| Total | 247 | 141 | 90 | 478 |

## Example 1: Computing the $\chi^2$ statistic

  * The $\chi^2$ statistic.
    $$\chi^2_{k} = \frac{(63-61)^2}{61} + \frac{(31-35)^2}{35} + \cdots + \frac{(32-34)^2}{34} = 0.967$$
    
  * Degrees of freedom.
    $$k = (3-1) \times (3-1) = 2(2) = 4$$

## Example 1: Computing the p-value

  * $\chi^2_{k} = 1.3121$ and $k = 4$
  
  * We can use the `pchisq` function in R.
  
```{r echo=TRUE}
df <- 4
1-pchisq(0.967,df)
```
    The p-value of 0.9148.
    
  * Note that **in a chi-squared analysis, the p-value is the probability of obtaining a chi-square as large or larger than that in the current experiment.**
    
```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.width=7,fig.height=3,out.width='100%'}
# normal pdf
df <- 4
x_chisq <- seq(0,30,0.10)
chisq_pdf <- dchisq(x_chisq,df)

# convert pdf into tibble
df_chisq <- tibble(z=x_chisq, chisq_pdf=chisq_pdf)

# plot the Bernoulli distribution and store it into a R variable
p1 <- ggplot(df_chisq,aes(x=z,y=chisq_pdf)) + 
  geom_line(color="#009159",linewidth=1) + 
  geom_ribbon(data=subset(df_chisq,z>=0.967),aes(x=z,ymax=dchisq(z,df)),ymin=0,alpha=0.3,fill="#009159") +
  xlab(TeX("$\\chi^2$")) +
  ylab("density") + 
  ggtitle("Chi-Squared Distribution with 4 Degrees of Freedom") + # sets the title of the plot
  scale_x_discrete(limits=c(0.967)) + 
  theme_minimal() + # set theme of entire plot
  theme(legend.title=element_blank())

# display plot
p1
```

## Example 1: Conclusion

  * Do these data provide evidence to suggest that goals vary by grade?
    $$H_0: \text{Grade and goals are independent.  Goals do not vary by grade.}$$
  	$$H_A: \text{Grade and goals are dependent.  Goals vary by grade}$$
  	
  * Since the p-value is large, we fail to reject $H_0$. The data do not provide convincing evidence that grade and goals are dependent. It doesn't appear that goals vary by grade.

## Example 2

The problem shown below was taken and slightly modified from your textbook [OpenIntro: Introduction to Modern Statistics Section 18.4](https://openintro-ims.netlify.app/inference-one-prop.html#chp16-exercises){target="_blank"}. Consider the research study described below.

**Coffee and Depression.**
    
> Researchers conducted a study investigating the relationship between caffeinated coffee consumption and risk of depression in women. They collected data on 50,739 women free of depression symptoms at the start of the study in the year 1996, and these women were followed through 2006. The researchers used questionnaires to collect data on caffeinated coffee consumption, asked each individual about physician- diagnosed depression, and also asked about the use of antidepressants. The table below shows the distribution of incidences of depression by amount of caffeinated coffee consumption.  [Lucas et al. 2011](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1105943){target="_blank"}

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(kableExtra)

tribble(
  ~`Clinical depression`, ~`1 cup / week or fewer`, ~`2-6 cups / week`, ~`1 cups / day`, ~`2-3 cups / day`, ~`4 cups / day or more`, ~Total,
  "Yes",                 670,          373,        905,           564,         95,   2607,
  "No",                11545,        6244,      16329,         11726,       2288,  48132,
  "Total",             12215,        6617,      17234,         12290,       2383,  50739
) %>%
  kbl(linesep = "", booktabs = TRUE, align = "lrrrrrr", format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                latex_options = "HOLD_position", 
                full_width = FALSE) %>%
  column_spec(1, width = "1em") %>%
  column_spec(2:6, width = "3em") %>%
  column_spec(7, width = "5em") %>%
  add_header_above(c(" " = 1, "Caffeinated coffee consumption" = 5, " " = 1))
```

  1. Compute the test statistic. What is the p-value?

  2. What is the conclusion of the hypothesis test?

## Example 2: Results

  * $\chi^2 =20.932$ and degrees of freedom is $k =4$
  
  * p-value: 
  
```{r}
df <- 4
1-pchisq(20.932,4)
```
  
  * Therefore, p-value is small and we reject $H_0$. The data provide convincing evidence to suggest that caffeinated coffee consumption and depression in women are associated.

## Activity: Test Independence for Two-Way Tables

1. Make sure you have a copy of the *F 3/21 Worksheet*. This will be handed out physically and it is also digitally available on Moodle.
2. Work on your worksheet by yourself for 10 minutes. Please read the instructions carefully. Ask questions if anything need clarifications.
3. Get together with another student.
4. Discuss your results.
5. Submit your worksheet on Moodle as a `.pdf` file.

## References

::: {#refs}
:::
